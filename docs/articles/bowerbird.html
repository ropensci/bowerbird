<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Bowerbird • bowerbird</title>
<!-- jquery --><script src="https://code.jquery.com/jquery-3.1.0.min.js" integrity="sha384-nrOSfDHtoPMzJHjVTdCopGqIqeYETSXhZDFyniQ8ZHcVy08QesyHcnOUpMpqnmWq" crossorigin="anonymous"></script><!-- Bootstrap --><link href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-BVYiiSIFeK1dGmJRAkycuHAHRg32OmUcww7on3RYdg4Va+PmSTsz/K68vbdEjh4u" crossorigin="anonymous">
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.7/js/bootstrap.min.js" integrity="sha384-Tc5IQib027qvyjSMfHjOMaLkfuWVxZxUPnCJA7l2mCWNIpG9mGCD8wGNIcPD7Txa" crossorigin="anonymous"></script><!-- Font Awesome icons --><link href="https://maxcdn.bootstrapcdn.com/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" integrity="sha384-T8Gy5hrqNKT+hzMclPo118YTQO6cYprQmhrYwIiQ/3axmI1hQomh7Ud2hPOy8SP1" crossorigin="anonymous">
<!-- pkgdown --><link href="../pkgdown.css" rel="stylesheet">
<script src="../jquery.sticky-kit.min.js"></script><script src="../pkgdown.js"></script><!-- mathjax --><script src="https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <div class="container template-vignette">
      <header><div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="../index.html">bowerbird</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
<li>
  <a href="../index.html">
    <span class="fa fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../articles/bowerbird.html">Get Started</a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
<li>
      <a href="../articles/data_provenance.html">Data provenance</a>
    </li>
  </ul>
</li>
      </ul>
<ul class="nav navbar-nav navbar-right">
<li>
  <a href="https://github.com/AustralianAntarcticDivision/bowerbird">
    <span class="fa fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>
<!--/.nav-collapse -->
  </div>
<!--/.container -->
</div>
<!--/.navbar -->

      
      </header><div class="row">
  <div class="col-md-9">
    <div class="page-header toc-ignore">
      <h1>Bowerbird</h1>
                        <h4 class="author">Ben Raymond, Michael Sumner</h4>
            
            <h4 class="date">2018-02-19</h4>
          </div>

    
    
<div class="contents">
<div id="bowerbird" class="section level1">
<h1 class="hasAnchor">
<a href="#bowerbird" class="anchor"></a>Bowerbird</h1>
<p>Often it’s desirable to have local copies of third-party data sets. Fetching data on the fly from remote sources can be a great strategy, but for speed or other reasons it may be better to have local copies. This is particularly common in environmental and other sciences that deal with large data sets (e.g. satellite or global climate model products). Bowerbird is an R package for maintaining a local collection of data sets from a range of data providers.</p>
<p>Bowerbird can be used in several different modes:</p>
<ul>
<li>interactively from the R console, to download or update data files on an as-needed basis</li>
<li>from the command line, perhaps as a regular scheduled task</li>
<li>programatically, including from within other R packages, scripts, or R markdown documents that require local copies of particular data files.</li>
</ul>
<p>When might you consider using bowerbird rather than, say, <a href="https://cran.r-project.org/package=curl">curl</a> or <a href="https://cran.r-project.org/package=crul">crul</a>? The principal advantage of bowerbird is that it can download files recursively. In many cases, it is only necessary to specify the top-level URL, and bowerbird can recursively download linked resources. Bowerbird can also:</p>
<ul>
<li><p>decompress downloaded files (if the remote server provides them in, say, zipped or gzipped form).</p></li>
<li><p>incrementally update files that you have previously downloaded. Bowerbird can be instructed not to re-download files that exist locally, unless they have changed on the remote server. Compressed files will also only be decompressed if changed.</p></li>
</ul>
<div id="installing" class="section level2">
<h2 class="hasAnchor">
<a href="#installing" class="anchor"></a>Installing</h2>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">install.packages</span>(<span class="st">"devtools"</span>)
<span class="kw">library</span>(devtools)
<span class="kw"><a href="http://www.rdocumentation.org/packages/devtools/topics/install_github">install_github</a></span>(<span class="st">"AustralianAntarcticDivision/bowerbird"</span>,<span class="dt">build_vignettes=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>You will also need to have the third-party utility <code>wget</code> available, because bowerbird uses this to do the heavy lifting of recursively downloading files from data providers. Note that installing <code>wget</code> may require admin privileges on your local machine.</p>
<div id="linux" class="section level3">
<h3 class="hasAnchor">
<a href="#linux" class="anchor"></a>Linux</h3>
<p><code>wget</code> is typically installed by default on Linux. Otherwise use your package manager to install it, e.g. <code>sudo apt install wget</code> on Ubuntu/Debian or <code>sudo yum install wget</code> on Fedora/CentOS.</p>
</div>
<div id="windows" class="section level3">
<h3 class="hasAnchor">
<a href="#windows" class="anchor"></a>Windows</h3>
<p>On Windows you can use the <code><a href="../reference/bb_install_wget.html">bb_install_wget()</a></code> function to install it. Otherwise download <code>wget</code> yourself (e.g. from <a href="https://eternallybored.org/misc/wget/" class="uri">https://eternallybored.org/misc/wget/</a>) and make sure it is on your system path.</p>
</div>
<div id="mac" class="section level3">
<h3 class="hasAnchor">
<a href="#mac" class="anchor"></a>Mac</h3>
<p>Use <code>brew install wget</code> or try <code>brew install --with-libressl wget</code> if you get SSL-related errors. If you do not have brew installed, see <a href="https://brew.sh/" class="uri">https://brew.sh/</a>.</p>
</div>
</div>
<div id="usage-overview" class="section level2">
<h2 class="hasAnchor">
<a href="#usage-overview" class="anchor"></a>Usage overview</h2>
<div id="configuration" class="section level3">
<h3 class="hasAnchor">
<a href="#configuration" class="anchor"></a>Configuration</h3>
<p>Build up a configuration by first defining global options such as the destination on your local file system:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(bowerbird)
my_directory &lt;-<span class="st"> "~/my/data/directory"</span>
cf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_config.html">bb_config</a></span>(<span class="dt">local_file_root=</span>my_directory)</code></pre></div>
<p>Bowerbird must then be told which data sources to synchronize. Let’s use data from the Australian 2016 federal election, which is provided as one of the example data sources:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">my_source &lt;-<span class="st"> </span><span class="kw">subset</span>(<span class="kw"><a href="../reference/bb_example_sources.html">bb_example_sources</a></span>(),id<span class="op">==</span><span class="st">"aus-election-house-2016"</span>)

## add this data source to the configuration
cf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_add.html">bb_add</a></span>(cf,my_source)</code></pre></div>
<p>Once the configuration has been defined and the data source added to it, we can run the sync process. We set <code>verbose=TRUE</code> here so that we see additional progress output:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">status &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_sync.html">bb_sync</a></span>(cf,<span class="dt">verbose=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>Congratulations! You now have your own local copy of your chosen data set. This particular example is fairly small (about 10MB), so it should not take too long to download. The files in this data set have been stored in a data-source-specific subdirectory of our local file root:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw"><a href="../reference/bb_data_source_dir.html">bb_data_source_dir</a></span>(cf)</code></pre></div>
<p>The contents of that directory:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">list.files</span>(<span class="kw"><a href="../reference/bb_data_source_dir.html">bb_data_source_dir</a></span>(cf),<span class="dt">recursive=</span><span class="ot">TRUE</span>,<span class="dt">full.names=</span><span class="ot">TRUE</span>)</code></pre></div>
<p>At a later time you can re-run this synchronization process. If the remote files have not changed, and assuming that your configuration has the <code>clobber</code> parameter set to 0 (“do not overwrite existing files”) or 1 (“overwrite only if the remote file is newer than the local copy”) then the sync process will run more quickly because it will not need to re-download any data files.</p>
</div>
</div>
<div id="users-level-of-usage-and-expected-knowledge" class="section level2">
<h2 class="hasAnchor">
<a href="#users-level-of-usage-and-expected-knowledge" class="anchor"></a>Users: level of usage and expected knowledge</h2>
<p>Users can interact with bowerbird at several levels, with increasing levels of complexity:</p>
<ol style="list-style-type: decimal">
<li><p><strong>Using bowerbird with data source definitions that have been written by someone else</strong>. This is fairly straightforward. The trickiest part might be ensuring that <code>wget</code> is installed (particularly on Mac machines).</p></li>
<li><p><strong>Writing your own data source definitions so that you can download data from a new data provider, but using an existing handler such as <code>bb_handler_wget</code></strong>. This is a little more complicated. You will need reasonable knowledge of how your data provider disseminates its files (including e.g. the source URL from which data files are to be downloaded, and how the data repository is structured). Be prepared to fiddle with <code>wget</code> settings to accommomdate provider-specific requirements (e.g. controlling recursion behaviour). The “Defining data sources” section below provides guidance and examples on writing data source definitions.</p></li>
<li><p><strong>Writing your own handler function for data providers that do not play nicely with the packaged handlers (<code>bb_handler_wget</code>, <code>bb_handler_oceandata</code>, <code>bb_handler_earthdata</code>)</strong>. This is the trickiest, and at the time of writing we have not provided much guidance on how to do this. See the “Writing new data source handlers” section, below.</p></li>
</ol>
<p>It is expected that the majority of users will fall into one of the first two categories.</p>
</div>
<div id="defining-data-sources" class="section level2">
<h2 class="hasAnchor">
<a href="#defining-data-sources" class="anchor"></a>Defining data sources</h2>
<div id="prepackaged-data-source-definitions" class="section level3">
<h3 class="hasAnchor">
<a href="#prepackaged-data-source-definitions" class="anchor"></a>Prepackaged data source definitions</h3>
<p>A few example data source definitions are provided as part of the bowerbird package — see <code><a href="../reference/bb_example_sources.html">bb_example_sources()</a></code> (these are also listed at the bottom of this document). Other packages (e.g. <a href="https://github.com/AustralianAntarcticDivision/blueant">blueant</a>) provide themed sets of data sources that can be used with bowerbird.</p>
</div>
<div id="defining-your-own-data-sources" class="section level3">
<h3 class="hasAnchor">
<a href="#defining-your-own-data-sources" class="anchor"></a>Defining your own data sources</h3>
<p>The general bowerbird workflow is to build up a configuration with one or more data sources, and pass that configuration object to the <code>bb_sync</code> function to kick off the download process. Each data source contains the details required by bowerbird to be able to fetch it, including a <em>handler</em> function that bb_sync will call to do the actual download.</p>
<p>The <code>bb_handler_wget</code> function is a generic handler function that will be suitable for many data sources. Note that this <code>bb_handler_wget</code> function is not intended to be called directly by the user, but is specified as part of a data source specification. The <code>bb_sync</code> function calls <code>bb_handler_wget</code> during its run, passing appropriate parameters as it does so.</p>
<p><code>bb_handler_wget</code> is a wrapper around the <code>wget</code> utility. The philosophy of bowerbird is to use <code>wget</code> as much as possible to handle web transactions. Using <code>wget</code> (and in particular its recursive download functionality) simplifies the process of writing and maintaining data source definitions. Typically, one only needs to define a data source in terms of its top-level URL and appropriate flags to pass to <code>wget</code>, along with some basic metadata (primarily intended to be read by the user).</p>
<p>Specifying a data source is done by the <code>bb_source</code> function. This can seem a little daunting, so let’s work through some examples. Most of these examples are included in <code><a href="../reference/bb_example_sources.html">bb_example_sources()</a></code>.</p>
<div id="example-1-a-single-data-file" class="section level4">
<h4 class="hasAnchor">
<a href="#example-1-a-single-data-file" class="anchor"></a>Example 1: a single data file</h4>
<p>Say we’ve found <a href="https://doi.org/10.4225/25/53D9B12E0F96E">this bathymetric data set</a> and we want to define a data source for it. It’s a single zip file that contains some ArcGIS binary grids. A minimal data source definition might look like this:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">src1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_source.html">bb_source</a></span>(
    <span class="dt">name=</span><span class="st">"Geoscience Australia multibeam bathymetric grids of the Macquarie Ridge"</span>,
    <span class="dt">id=</span><span class="st">"10.4225/25/53D9B12E0F96E"</span>,
    <span class="dt">doc_url=</span><span class="st">"https://doi.org/10.4225/25/53D9B12E0F96E"</span>,
    <span class="dt">license=</span><span class="st">"CC-BY 4.0"</span>,
    <span class="dt">citation=</span><span class="st">"Spinoccia, M., 2012. XYZ multibeam bathymetric grids of the Macquarie Ridge. Geoscience Australia, Canberra."</span>,
    <span class="dt">source_url=</span><span class="st">"http://www.ga.gov.au/corporate_data/73697/Macquarie_ESRI_Raster.zip"</span>,
    <span class="dt">method=</span><span class="kw">list</span>(<span class="st">"bb_handler_wget"</span>))</code></pre></div>
<p>The parameters provided here are all mandatory:</p>
<ul>
<li>
<code>id</code> is a unique identifier for the dataset, and should be something that changes when the data set is updated. Its DOI, if it has one, is ideal for this. Otherwise, if the original data provider has an identifier for this dataset, that is probably a good choice here (include the data version number if there is one)</li>
<li>
<code>name</code> is a human-readable but still unique identifier</li>
<li>
<code>doc_url</code> is a link to a metadata record or documentation page that describes the data in detail</li>
<li>
<code>license</code> is the license under which the data are being distributed, and is required so that users are aware of the conditions that govern the usage of the data</li>
<li>
<code>citation</code> gives citation details for the data source. It’s generally considered good practice to cite data providers, and indeed under some data licenses this is in fact mandatory</li>
<li>the <code>method</code> parameter is specified as a list, where the first entry is the name of the handler function that will be used to retrieve this data set (<code>bb_handler_wget</code>, in this case)and the remaining entries are data-source-specific arguments to pass to that function (none here)</li>
<li>and finally the <code>source_url</code> tells bowerbird where to go to get the data.</li>
</ul>
<p>Add this data source to a configuration and synchronize it:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_config.html">bb_config</a></span>(<span class="st">"c:/temp/data/bbtest"</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/bb_add.html">bb_add</a></span>(src1)
status &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_sync.html">bb_sync</a></span>(cf)</code></pre></div>
<p>This should have caused the zip file to be downloaded the zip file to your local machine, in this case into the <code>c:/temp/data/bbtest/www.ga.gov.au/corporate_data/73697</code> directory.</p>
<p>There are a few additional entries that we might consider for this data source, particularly if we are going to make it available for other users.</p>
<p>Firstly, having the zip file locally is great, but we will need to unzip it before we can actually use it. Bowerbird can do this by specifying a <code>postprocess</code> action:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">src1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_source.html">bb_source</a></span>(..., <span class="dt">postprocess=</span><span class="kw">list</span>(<span class="st">"bb_unzip"</span>))</code></pre></div>
<p>For the benefit of other users, we might also add the <code>description</code>, <code>collection_size</code>, and <code>data_group</code> parameters:</p>
<ul>
<li>
<code>description</code> provides a plain-language description of the data set, so that users can get an idea of what it contains (for full details they can consult the <code>doc_url</code> link that you already provided)</li>
<li>
<code>collection_size</code> is the approximate disk space (in GB) used by the data collection. Some collections are very large! This parameter obviously gives an indication of the storage space required, but also the download size (noting though that some data sources deliver compressed files, so the download size might be much smaller)</li>
<li>
<code>data_group</code> is a descriptive or thematic group name that this data set belongs to. This can also help users find data sources of interest to them</li>
<li>
<code>access_function</code> can be used to suggest to users an appropriate function to read these data files. In this case the files can be read by the <code>raster</code> function (from the <code>raster</code> package).</li>
</ul>
<p>So our full data source definition now looks like:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">src1 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_source.html">bb_source</a></span>(
    <span class="dt">name=</span><span class="st">"Geoscience Australia multibeam bathymetric grids of the Macquarie Ridge"</span>,
    <span class="dt">id=</span><span class="st">"10.4225/25/53D9B12E0F96E"</span>,
    <span class="dt">description=</span><span class="st">"This is a compilation of all the processed multibeam bathymetry data that are publicly available in Geoscience Australia's data holding for the Macquarie Ridge."</span>,
    <span class="dt">doc_url=</span><span class="st">"https://doi.org/10.4225/25/53D9B12E0F96E"</span>,
    <span class="dt">license=</span><span class="st">"CC-BY 4.0"</span>,
    <span class="dt">citation=</span><span class="st">"Spinoccia, M., 2012. XYZ multibeam bathymetric grids of the Macquarie Ridge. Geoscience Australia, Canberra."</span>,
    <span class="dt">source_url=</span><span class="st">"http://www.ga.gov.au/corporate_data/73697/Macquarie_ESRI_Raster.zip"</span>,
    <span class="dt">method=</span><span class="kw">list</span>(<span class="st">"bb_handler_wget"</span>),
    <span class="dt">postprocess=</span><span class="kw">list</span>(<span class="st">"bb_unzip"</span>),
    <span class="dt">collection_size=</span><span class="fl">0.4</span>,
    <span class="dt">access_function=</span><span class="st">"raster::raster"</span>,
    <span class="dt">data_group=</span><span class="st">"Topography"</span>)</code></pre></div>
</div>
<div id="example-2-multiple-files-via-recursive-download" class="section level4">
<h4 class="hasAnchor">
<a href="#example-2-multiple-files-via-recursive-download" class="anchor"></a>Example 2: multiple files via recursive download</h4>
<p>This data source (Australian Election 2016 House of Representatives data) is provided as one of the example data sources in <code><a href="../reference/bb_example_sources.html">bb_example_sources()</a></code>, but let’s look in a little more detail here.</p>
<p>The primary entry point to this data set is an HTML index page, which links to a number of data files. In principle we could generate a list of all of these data files and download them one by one, but that would be tedious and prone to breaking (if the data files changed our hard-coded list would no longer be correct). Instead we can start at the HTML index and recursively download linked data files.</p>
<p>The definition for this data source is:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">src2 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_source.html">bb_source</a></span>(
    <span class="dt">name=</span><span class="st">"Australian Election 2016 House of Representatives data"</span>,
    <span class="dt">id=</span><span class="st">"aus-election-house-2016"</span>,
    <span class="dt">description=</span><span class="st">"House of Representatives results from the 2016 Australian election."</span>,
    <span class="dt">doc_url=</span><span class="st">"http://results.aec.gov.au/"</span>,
    <span class="dt">citation=</span><span class="st">"Copyright Commonwealth of Australia 2017. As far as practicable, material for which the copyright is owned by a third party will be clearly labelled. The AEC has made all reasonable efforts to ensure that this material has been reproduced on this website with the full consent of the copyright owners."</span>,
    <span class="dt">source_url=</span><span class="kw">c</span>(<span class="st">"http://results.aec.gov.au/20499/Website/HouseDownloadsMenu-20499-Csv.htm"</span>),
    <span class="dt">license=</span><span class="st">"CC-BY"</span>,
    <span class="dt">method=</span><span class="kw">list</span>(<span class="st">"bb_handler_wget"</span>,<span class="dt">recursive=</span><span class="ot">TRUE</span>,<span class="dt">level=</span><span class="dv">1</span>,<span class="dt">accept=</span><span class="st">"csv"</span>,<span class="dt">reject_regex=</span><span class="st">"Website/UserControls"</span>),
    <span class="dt">collection_size=</span><span class="fl">0.01</span>)</code></pre></div>
<p>Most of these parameters will be familiar from the previous example, but the <code>method</code> definition is more complex. Let’s look at the entries in the <code>method</code> list (these are all parameters that get passed to the <code><a href="../reference/bb_wget.html">bb_wget()</a></code> function, so you can find more information about these via <code><a href="http://www.rdocumentation.org/packages/devtools/topics/help">help("bb_wget")</a></code>):</p>
<ul>
<li>
<code>recursive=TRUE</code> tells <code>wget</code> that we want to recursively download multiple files, starting from the <code>source_url</code>. The <code>source_url</code> points to a html page that contains links to csv files, and it’s the csv files that actually contain the data of interest, so we want to follow the links from the html file to the csv files</li>
<li>
<code>level=1</code> specifies that <code>wget</code> should only recurse down one level (i.e. follow links found in the top-level <code>source_url</code> document, but don’t recurse any deeper. If, say, we specified <code>level=2</code>, then <code>wget</code> would follow links from the top-level document as well as links found in those linked documents.) Recursion <code>level=1</code> is the default value, to help avoid very large but unintentional downloads</li>
<li>
<code>accept="csv"</code> means that we only want <code>wget</code> to retrieve csv files. Links to html files or directories will typically be followed even if they do not match the <code>accept</code> criteria, because they might contain links that are wanted</li>
<li>
<code>reject_regex="Website/UserControls"</code> - this one is slightly esoteric: the top-level document contains this link, but the link does not actually exist on the server. When <code>wget</code> tries to retrieve it, the remote server issues a “404 not found” error which causes our <code>bb_sync</code> process to think that is has failed! Since this link isn’t actually part of our desired data, we can just exclude it with the <code>reject_regex</code> parameter, which avoids the error.</li>
</ul>
<p>Add this data source to a configuration and synchronize it:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_config.html">bb_config</a></span>(<span class="st">"c:/temp/data/bbtest"</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/bb_add.html">bb_add</a></span>(src2)
status &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_sync.html">bb_sync</a></span>(cf)</code></pre></div>
<p>Once again the data have been saved into a subdirectory that reflects the URL structure (<code>c:/temp/data/bbtest/results.aec.gov.au/20499/Website/Downloads</code>). If you examine that directory, you will see that it contains around 50 separate csv files, each containing a different component of the data set.</p>
<p>You can immediately see that by using a recursive download, not only did we not need to individually specify all 50 of those data files, but if the data provider adds new files in the future the recursive download process will automatically find them (so long as they are linked from the top-level <code>source_url</code> document).</p>
</div>
<div id="example-3-an-earthdata-source" class="section level4">
<h4 class="hasAnchor">
<a href="#example-3-an-earthdata-source" class="anchor"></a>Example 3: an Earthdata source</h4>
<p>The <a href="https://earthdata.nasa.gov/">Earthdata system</a> is one of NASA’s data management systems and home to a vast range of Earth science data from satellites, aircraft, field measurements, and other sources. Say you had a rummage through their <a href="https://search.earthdata.nasa.gov/">data catalogue</a> and found yourself wanting a copy of <a href="http://doi.org/10.5067/EYICLBOAAJOU">Sea Ice Trends and Climatologies from SMMR and SSM/I-SSMIS</a>.</p>
<p>Data sources served through the Earthdata system require users to have an Earthdata account, and to log in with their credential when downloading data. Bowerbird’s <code>bb_handler_earthdata</code> function eases some of the hassle involved with these Earthdata sources.</p>
<p>First, let’s create an account and get ourselves access to the data.</p>
<ol style="list-style-type: decimal">
<li><p>create an Earthdata login via <a href="https://wiki.earthdata.nasa.gov/display/EL/How+To+Register+With+Earthdata+Login" class="uri">https://wiki.earthdata.nasa.gov/display/EL/How+To+Register+With+Earthdata+Login</a> if you don’t already have one</p></li>
<li><p>we need to know the URL of the actual data. The <a href="http://doi.org/10.5067/EYICLBOAAJOU">metadata record</a> for this data set contains a “Get data” button, which in turn directs the user to this URL: <a href="https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0192_seaice_trends_climo_v2/" class="uri">https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0192_seaice_trends_climo_v2/</a>. That’s the data URL (which will be used as the <code>source_url</code> in our data source definition)</p></li>
<li><p>browse to the <a href="https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0192_seaice_trends_climo_v2/">that data URL</a>, using your Earthdata login to authenticate. When you use access an Earthdata application for the first time, you will be requested to authorize it so that it can access data using your credentials (see <a href="https://wiki.earthdata.nasa.gov/display/EL/How+To+Register+With+Earthdata+Login" class="uri">https://wiki.earthdata.nasa.gov/display/EL/How+To+Register+With+Earthdata+Login</a>). This dataset is served by the NSIDC DAAC application, so you will need to authorize this application (either through browsing as just described, or go to ‘My Applications’ at <a href="https://urs.earthdata.nasa.gov/profile" class="uri">https://urs.earthdata.nasa.gov/profile</a> and add the application ‘nsidc-daacdata’ to your list of authorized applications)</p></li>
</ol>
<p>You only need to create an Earthdata login once. If you want to download other Earthdata data sets via bowerbird, you’ll use the same credentials, but note that you may need to authorize additional applications, depending on where your extra data sets come from.</p>
<p>Now that we have access to the data, we can write our bowerbird data source:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">src3 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_source.html">bb_source</a></span>(
    <span class="dt">name=</span><span class="st">"Sea Ice Trends and Climatologies from SMMR and SSM/I-SSMIS, Version 2"</span>,
    <span class="dt">id=</span><span class="st">"10.5067/EYICLBOAAJOU"</span>,
    <span class="dt">description=</span><span class="st">"NSIDC provides this data set to aid in the investigations of the variability and trends of sea ice cover. Ice cover in these data are indicated by sea ice concentration: the percentage of the ocean surface covered by ice. The ice-covered area indicates how much ice is present; it is the total area of a pixel multiplied by the ice concentration in that pixel. Ice persistence is the percentage of months over the data set time period that ice existed at a location. The ice-extent indicates whether ice is present; here, ice is considered to exist in a pixel if the sea ice concentration exceeds 15 percent. This data set provides users with data about total ice-covered areas, sea ice extent, ice persistence, and monthly climatologies of sea ice concentrations."</span>,
    <span class="dt">doc_url=</span><span class="st">"https://doi.org/10.5067/EYICLBOAAJOU"</span>,
    <span class="dt">citation=</span><span class="st">"Stroeve, J. and W. Meier. 2017. Sea Ice Trends and Climatologies from SMMR and SSM/I-SSMIS, Version 2. [Indicate subset used]. Boulder, Colorado USA. NASA National Snow and Ice Data Center Distributed Active Archive Center. doi: http://dx.doi.org/10.5067/EYICLBOAAJOU. [Date Accessed]."</span>,
    <span class="dt">source_url=</span><span class="kw">c</span>(<span class="st">"https://daacdata.apps.nsidc.org/pub/DATASETS/nsidc0192_seaice_trends_climo_v2/"</span>),
    <span class="dt">license=</span><span class="st">"Please cite, see http://nsidc.org/about/use_copyright.html"</span>,
    <span class="dt">authentication_note=</span><span class="st">"Requires Earthdata login, see https://wiki.earthdata.nasa.gov/display/EL/How+To+Register+With+Earthdata+Login . Note that you will also need to authorize the application 'nsidc-daacdata' (see 'My Applications' at https://urs.earthdata.nasa.gov/profile)"</span>,
    <span class="dt">method=</span><span class="kw">list</span>(<span class="st">"bb_handler_earthdata"</span>,<span class="dt">recursive=</span><span class="ot">TRUE</span>,<span class="dt">level=</span><span class="dv">4</span>,<span class="dt">relative=</span><span class="ot">TRUE</span>),
    <span class="dt">user=</span><span class="st">"your_earthdata_username"</span>,
    <span class="dt">password=</span><span class="st">"your_earthdata_password"</span>,
    <span class="dt">collection_size=</span><span class="fl">0.02</span>,
    <span class="dt">data_group=</span><span class="st">"Sea ice"</span>)</code></pre></div>
<p>This is very similar to our previous examples, with these differences:</p>
<ul>
<li>the <code>method</code> specifies <code>bb_handler_earthdata</code> (whereas previously we used <code>bb_handler_wget</code>). The <code>bb_handler_earthdata</code> is actually very similar to <code>bb_handler_wget</code>, but it takes care of some Earthdata-specific details like authentication using your Earthdata credentials</li>
<li>we want a <code>recursive=TRUE</code> download, because the data are arranged in subdirectories. Manual browsing of the data set indicates that we need four levels of recursion, hence <code>level=4</code>
</li>
<li>
<code>relative=TRUE</code> means that <code>wget</code> will only follow relative links (i.e. links of the form <code>&lt;a href="/some/directory/"&gt;...&lt;/a&gt;</code>, which by definition must be on the same server as our <code>source_url</code>). Absolute links (i.e. links of the form <code>&lt;a href="http://some.other.server/some/path"&gt;...&lt;/a&gt;</code> will not be followed. This is another mechanism to prevent the recursive download from downloading stuff we don’t want.</li>
</ul>
<p>Note that if you were providing this data source definition for other people to use, you would obviously not want to hard-code your Earthdata credentials in the <code>user</code> and <code>password</code> slots. In this case, specify the credentials as empty strings, and also include <code>warn_empty_auth=FALSE</code> in the data source definition (this suppresses the warning that <code>bb_source</code> would otherwise give you about missing credentials):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">src3 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_source.html">bb_source</a></span>(
    <span class="dt">name=</span><span class="st">"Sea Ice Trends and Climatologies from SMMR and SSM/I-SSMIS, Version 2"</span>,
   ... details as above...,
    <span class="dt">user=</span><span class="st">""</span>,
    <span class="dt">password=</span><span class="st">""</span>,
    <span class="dt">warn_empty_auth=</span><span class="ot">FALSE</span>)</code></pre></div>
<p>When another user wants to use this data source, they simply insert their own credentials, e.g.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mysrc &lt;-<span class="st"> </span>src3
mysrc<span class="op">$</span>user &lt;-<span class="st"> "theirusername"</span>
mysrc<span class="op">$</span>password &lt;-<span class="st"> "theirpassword"</span>

## then proceed as per usual
cf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_add.html">bb_add</a></span>(cf,mysrc)</code></pre></div>
</div>
<div id="example-4-an-oceandata-source" class="section level4">
<h4 class="hasAnchor">
<a href="#example-4-an-oceandata-source" class="anchor"></a>Example 4: an Oceandata source</h4>
<p>NASA’s <a href="https://oceandata.sci.gsfc.nasa.gov/">Oceandata</a> system provides access to a range of satellite-derived marine data products. The <code>bb_oceandata_handler</code> can be used to download these data. It uses a two-step process: first it makes a query to the Oceancolour data file search tool (<a href="https://oceandata.sci.gsfc.nasa.gov/search/file_search.cgi" class="uri">https://oceandata.sci.gsfc.nasa.gov/search/file_search.cgi</a>) to find files that match your specified criterion, and then downloads the matching files.</p>
<p>Oceandata uses standardized file naming conventions (see <a href="https://oceancolor.gsfc.nasa.gov/docs/format/" class="uri">https://oceancolor.gsfc.nasa.gov/docs/format/</a>), so once you know which products you want you can construct a suitable file name pattern to search for. For example, “S*L3m_MO_CHL_chlor_a_9km.nc" would match monthly level-3 mapped chlorophyll data from the SeaWiFS satellite at 9km resolution, in netcdf format. This pattern is passed as the <code>search</code> argument to the <code>bb_handler_oceandata</code> handler function. Note that the <code>bb_handler_oceandata</code> does not need a <code>source_url</code> to be specified in the <code>bb_source</code> call.</p>
<p>Here, for the sake of a small example, we’ll limit ourselves to a single file (“T20000322000060.L3m_MO_SST_sst_9km.nc”, which is sea surface temperature from the Terra satellite in February 2000):</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">src4 &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_source.html">bb_source</a></span>(
    <span class="dt">name=</span><span class="st">"Oceandata test file"</span>,
    <span class="dt">id=</span><span class="st">"oceandata-test"</span>,
    <span class="dt">description=</span><span class="st">"Monthly, 9km remote-sensed sea surface temperature from the MODIS Terra satellite"</span>,
    <span class="dt">doc_url=</span> <span class="st">"https://oceancolor.gsfc.nasa.gov/"</span>,
    <span class="dt">citation=</span><span class="st">"See https://oceancolor.gsfc.nasa.gov/cms/citations"</span>,
    <span class="dt">license=</span><span class="st">"Please cite"</span>,
    <span class="dt">method=</span><span class="kw">list</span>(<span class="st">"bb_handler_oceandata"</span>,<span class="dt">search=</span><span class="st">"T20000322000060.L3m_MO_SST_sst_9km.nc"</span>),
    <span class="dt">data_group=</span><span class="st">"Sea surface temperature"</span>)

## add this source to a configuration and synchronize it:
cf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_config.html">bb_config</a></span>(<span class="st">"c:/temp/data/bbtest"</span>) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/bb_add.html">bb_add</a></span>(src4)
status &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_sync.html">bb_sync</a></span>(cf)

## and now we can see our local copy of this data file:
<span class="kw">dir</span>(<span class="kw"><a href="../reference/bb_data_source_dir.html">bb_data_source_dir</a></span>(cf),<span class="dt">recursive=</span><span class="ot">TRUE</span>)</code></pre></div>
</div>
</div>
</div>
<div id="nuances" class="section level2">
<h2 class="hasAnchor">
<a href="#nuances" class="anchor"></a>Nuances</h2>
<p>Bowerbird hands off the complexities of recursive downloading to the <code>wget</code> utility. This allows bowerbird’s data source definitions to be fairly lightweight and more robust to changes by the data provider. However, one of the consequences of this approach is that bowerbird actually knows very little about the data files that it maintains, which can be limiting in some respects. It is not generally possible, for example, to provide the user with an indication of download progress (progress bar or similar) for a given data source because neither bowerbird nor <code>wget</code> actually know in advance how many files are in it or how big they are. Data sources do have a <code>collection_size</code> entry, to give the user some indication of the disk space required, but this is only approximate (and must be hand-coded by the data source maintainer). See the ‘Reducing download sizes’ section below for tips on retrieving only a subset of a large data source.</p>
<div id="wget-gotchas" class="section level3">
<h3 class="hasAnchor">
<a href="#wget-gotchas" class="anchor"></a>wget gotchas</h3>
<p><code>wget</code> is a complicated beast with many command-line options and sometimes inconsistent behaviour. The handler functions (<code>bb_handler_wget</code>, <code>bb_handler_earthdata</code>, <code>bb_handler_oceandata</code>) interact with <code>wget</code> via the intermediate <code>bb_wget</code> function, which provides an R interface to <code>wget</code>. The arguments to this function (see <code><a href="http://www.rdocumentation.org/packages/devtools/topics/help">help("bb_wget")</a></code>) are almost all one-to-one mappings of <code>wget</code>’s own command-line parameters. You can find more information about <code>wget</code> via the <a href="https://www.gnu.org/software/wget/manual/wget.html">wget manual</a> or one of the many online tutorials. You can also see the in-built wget help by running <code><a href="../reference/bb_wget.html">bb_wget("--help")</a></code>.</p>
<p>Remember that any <code>wget_global_flags</code> defined via <code>bb_config</code> will be applied to every data source in addition to their specific <code>method</code> flags.</p>
<p>The most relevant command-line <code>wget</code> command-line options are exposed through arguments to the <code>bb_wget</code> function. A few comments on <code>wget</code> behaviour and some of its command line options are provided below.</p>
<div id="recursive-download" class="section level4">
<h4 class="hasAnchor">
<a href="#recursive-download" class="anchor"></a>Recursive download</h4>
<ul>
<li>
<code>recursive=TRUE</code> is the default for <code>bb_wget</code> — you will probably want this even if the data source doesn’t strictly require a recursive download. The synchronization process saves files relative to the <code>local_file_root</code> directory specified in <code>bb_config</code>. If <code>recursive=TRUE</code>, then wget creates a directory structure that follows the URL structure. For example, calling <code><a href="../reference/bb_wget.html">bb_wget("http://www.somewhere.org/monkey/banana/dataset.zip",recursive=TRUE)</a></code> will save the local file <code>www.somewhere.org/monkey/banana/dataset.zip</code>. Thus, <code>recursive=TRUE</code> will keep data files from different sources naturally separated into their own directories. Without this flag, you are likely to get all downloaded files saved into your <code>local_file_root</code>
</li>
</ul>
<p>Recursion is a powerful tool but will sometimes download much more than you really wanted. There are various methods for restricting the recursion:</p>
<ul>
<li><p>if you want to include/exclude certain files from being downloaded, use the <code>accept</code>, <code>reject</code>, <code>accept_regex</code>, and <code>reject_regex</code> parameters. Note that <code>accept</code> and <code>reject</code> apply to file names (not the full path), and can be comma-separated lists of file name suffixes or patterns. The <code>accept_regex</code> and <code>reject_regex</code> parameters apply to the full path but can’t be comma-separated (you can specify multiple regular expressions as a character vector, e.g. <code>accept_regex=c("^foo","bar$")</code>)</p></li>
<li><p><code>no_parent=TRUE</code> prevents <code>wget</code> from ascending to a parent directory during its recursion process, because if it did so it would likely be downloading files that are not part of the data set that we want (this is <code>TRUE</code> by default).</p></li>
</ul>
</div>
<div id="other-wget-tips-and-tricks-including-resolving-recursive-download-issues" class="section level4">
<h4 class="hasAnchor">
<a href="#other-wget-tips-and-tricks-including-resolving-recursive-download-issues" class="anchor"></a>Other wget tips and tricks, including resolving recursive download issues</h4>
<p>Recursive download not working as expected, or other <code>wget</code> oddities?</p>
<ul>
<li><p><code>robots_off=TRUE</code>: by default wget considers itself to be a robot, and therefore won’t recurse into areas of a site that are excluded to robots. This can cause problems with servers that exclude robots (accidentally or deliberately) from parts of their sites containing data that we want to retrieve. Setting  to TRUE will add a “-e robots=off” flag, which instructs wget to behave as a human user, not a robot. See  for more information about robot exclusion</p></li>
<li><p>as noted above, <code>no_parent=TRUE</code> by default. In some cases, though, you might want the recursion to ascend to a parent directory, and therefore need to override the default setting</p></li>
<li><p>a known limitation of <code>wget</code> is that it will NOT follow symbolic links to directories on the remote server. If your recursive download is not descending into directories when you think it should, this might be the cause</p></li>
<li><p><code>no_if_modified_since=TRUE</code> may be useful when downloading files that have changed since last download (i.e. using ). The default method for doing this is to issue an “If-Modified-Since” header on the request, which instructs the remote server not to return the file if it has not changed since the specified date. Some servers do not support this header. In these cases, trying using , which will instead send a preliminary HEAD request to ascertain the date of the remote file</p></li>
<li><p><code>no_check_certificate=TRUE</code> will allow a download from a secure server to proceed even if the server’s certificate checks fail. This option might be useful if trying to download files from a server with an expired certificate, but it is clearly a security risk and so should be used with caution</p></li>
<li><p><code>adjust_extension</code>: if a file of type ‘application/xhtml+xml’ or ‘text/html’ is downloaded and the URL does not end with .htm or .html, setting <code>adjust_extension=TRUE</code> will cause the suffix ‘.html’ to be appended to the local filename. This can be useful when mirroring a remote site that has file URLs that conflict with directories. Say we are recursively downloading from <a href="http://somewhere.org/this/page" class="uri">http://somewhere.org/this/page</a>, which has further content below it at <a href="http://somewhere.org/this/page/more" class="uri">http://somewhere.org/this/page/more</a>. If “somewhere.org/this/page” is saved as a file with that name, that name can’t also be used as the local directory name in which to store the lower-level content. Setting  will cause the page to be saved as “somewhere.org/this/page.html”, thus resolving the conflict</p></li>
<li><p>setting <code>wait</code> will cause <code>wget</code> to pause for this number of seconds between successive retrievals. This option may help with servers that block multiple successive requests, by introducing a delay between requests</p></li>
<li><p>if <code>wget</code> is not behaving as expected, try adding <code>debug=TRUE</code>. This gives debugging output from <code>wget</code> itself (which is additional to the output obtained by calling <code><a href="../reference/bb_sync.html">bb_sync(...,verbose=TRUE)</a></code>).</p></li>
</ul>
</div>
</div>
<div id="choosing-a-data-directory" class="section level3">
<h3 class="hasAnchor">
<a href="#choosing-a-data-directory" class="anchor"></a>Choosing a data directory</h3>
<p>It’s up to you where you want your data collection kept, and to provide that location to bowerbird. A common use case for bowerbird is maintaining a central data collection for multiple users, in which case that location is likely to be some sort of networked file share. However, if you are keeping a collection for your own use, you might like to look at <a href="https://github.com/r-lib/rappdirs" class="uri">https://github.com/r-lib/rappdirs</a> to help find a suitable directory location.</p>
</div>
<div id="post-processing" class="section level3">
<h3 class="hasAnchor">
<a href="#post-processing" class="anchor"></a>Post-processing</h3>
<div id="decompressing-files" class="section level4">
<h4 class="hasAnchor">
<a href="#decompressing-files" class="anchor"></a>Decompressing files</h4>
<p>If the data source delivers compressed files, you will most likely want to decompress them after downloading. The postprocess options <code>bb_decompress</code>, <code>bb_unzip</code>, etc will do this for you. By default, these <em>do not</em> delete the compressed files after decompressing. The reason for this is so that on the next synchronization run, the local (compressed) copy can be compared to the remote compressed copy, and the download can be skipped if nothing has changed. Deleting local compressed files will save space on your file system, but may result in every file being re-downloaded on every synchronization run.</p>
<p>See <code><a href="http://www.rdocumentation.org/packages/devtools/topics/help">help("bb_unzip")</a></code> for more information, including usage examples.</p>
</div>
<div id="deleting-unwanted-files" class="section level4">
<h4 class="hasAnchor">
<a href="#deleting-unwanted-files" class="anchor"></a>Deleting unwanted files</h4>
<p>The <code>bb_cleanup</code> postprocessing option can be used to remove unwanted files after downloading. See See <code><a href="http://www.rdocumentation.org/packages/devtools/topics/help">help("bb_cleanup")</a></code>.</p>
</div>
</div>
<div id="modifying-data-sources" class="section level3">
<h3 class="hasAnchor">
<a href="#modifying-data-sources" class="anchor"></a>Modifying data sources</h3>
<div id="authentication" class="section level4">
<h4 class="hasAnchor">
<a href="#authentication" class="anchor"></a>Authentication</h4>
<p>Some data providers require users to log in. The <code>authentication_note</code> column in the configuration table should indicate when this is the case, including a reference (e.g. the URL via which an account can be obtained). For these sources, you will need to provide your user name and password, e.g.:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">mysrc &lt;-<span class="st"> </span><span class="kw">subset</span>(<span class="kw"><a href="../reference/bb_example_sources.html">bb_example_sources</a></span>(),name<span class="op">==</span><span class="st">"CMEMS global gridded SSH reprocessed (1993-ongoing)"</span>)
mysrc<span class="op">$</span>user &lt;-<span class="st"> "yourusername"</span>
mysrc<span class="op">$</span>password &lt;-<span class="st"> "yourpassword"</span>
cf &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_add.html">bb_add</a></span>(cf,mysrc)

## or, using dplyr
<span class="kw">library</span>(dplyr)
mysrc &lt;-<span class="st"> </span><span class="kw"><a href="../reference/bb_example_sources.html">bb_example_sources</a></span>() <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/filter.html">filter</a></span>(name<span class="op">==</span><span class="st">"CMEMS global gridded SSH reprocessed (1993-ongoing)"</span>) <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span>(<span class="dt">user=</span><span class="st">"yourusername"</span>,<span class="dt">password=</span><span class="st">"yourpassword"</span>)
cf &lt;-<span class="st"> </span>cf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/bb_add.html">bb_add</a></span>(mysrc)</code></pre></div>
</div>
<div id="reducing-download-sizes" class="section level4">
<h4 class="hasAnchor">
<a href="#reducing-download-sizes" class="anchor"></a>Reducing download sizes</h4>
<p>Sometimes you might only want part of a data collection. Perhaps you only want a few years from a long-term collection, or perhaps the data are provided in multiple formats and you only need one. If the data source uses the <code>bb_handler_wget</code> method, you can restrict what is downloaded by modifying the arguments passed through the data source’s <code>method</code> parameter, particularly the <code>accept</code>, <code>reject</code>, <code>accept_regex</code>, and <code>reject_regex</code> options. If you are modifying an existing data source configuration, you most likely want to leave the original method flags intact and just add extra flags.</p>
<p>Say a particular data provider arranges their files in yearly directories. It would be fairly easy to restrict ourselves to, say, only the 2017 data:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(dplyr)
mysrc &lt;-<span class="st"> </span>mysrc <span class="op">%&gt;%</span>
<span class="st">  </span><span class="kw"><a href="http://dplyr.tidyverse.org/reference/mutate.html">mutate</a></span>(<span class="dt">method=</span><span class="kw">c</span>(method,<span class="kw">list</span>(<span class="dt">accept_regex=</span><span class="st">"/2017/"</span>)))
cf &lt;-<span class="st"> </span>cf <span class="op">%&gt;%</span><span class="st"> </span><span class="kw"><a href="../reference/bb_add.html">bb_add</a></span>(mysrc)</code></pre></div>
<p>See the notes above for further guidance on the accept/reject flags.</p>
<p>Alternatively, for data sources that are arranged in subdirectories, one could replace the <code>source_url</code> with one or more that point to the specific subdirectories that are wanted.</p>
</div>
</div>
<div id="parallelized-sync" class="section level3">
<h3 class="hasAnchor">
<a href="#parallelized-sync" class="anchor"></a>Parallelized sync</h3>
<p>If you have many data sources in your configuration, running the sync in parallel is likely to speed the process up considerably (unless your bandwidth is the limiting factor). A logical approach to this would be to split a configuration, with a subset of data sources in each (see <code>bb_subset</code>), and run those subsets in parallel. One potential catch to keep in mind would be data sources that hit the same remote data provider. If they overlap overlap in terms of the parts of the remote site that they are mirroring, that might invoke odd behaviour (race conditions, simultaneous downloads of the same file by different parallel processes, etc).</p>
</div>
<div id="data-provenance-and-reproducible-research" class="section level3">
<h3 class="hasAnchor">
<a href="#data-provenance-and-reproducible-research" class="anchor"></a>Data provenance and reproducible research</h3>
<p>An aspect of reproducible research is knowing which data were used to perform an analysis, and potentially archiving those data to an appropriate repository. Bowerbird can assist with this: see <code><a href="../articles/data_provenance.html">vignette("data_provenance")</a></code>.</p>
</div>
</div>
<div id="developer-notes" class="section level2">
<h2 class="hasAnchor">
<a href="#developer-notes" class="anchor"></a>Developer notes</h2>
<div id="writing-new-data-source-handlers" class="section level3">
<h3 class="hasAnchor">
<a href="#writing-new-data-source-handlers" class="anchor"></a>Writing new data source handlers</h3>
<p>The <code>bb_handler_wget</code> R function provides a wrapper around <code>wget</code> that should be sufficient for many data sources. However, some data sources can’t be retrieved using only simple <code>wget</code> calls, and so the <code>method</code> for such data sources will need to be something more elaborate than <code>bb_handler_wget</code>. Notes will be added here about defining new handler functions, but in the meantime look at <code>bb_handler_oceandata</code> and <code>bb_handler_earthdata</code>, which provide handlers for <a href="https://oceandata.sci.gsfc.nasa.gov/">Oceandata</a> and <a href="https://earthdata.nasa.gov/">Earthdata</a> data sources.</p>
</div>
</div>
<div id="data-source-summary" class="section level2">
<h2 class="hasAnchor">
<a href="#data-source-summary" class="anchor"></a>Data source summary</h2>
<p>The <code>bb_summary</code> function will produce a HTML or Rmarkdown summary of the data sources contained in a configuration object. If you are maintaining a data collection on behalf of other users, or even just for yourself, it may be useful to keep an up-to-date HTML summary of your repository in an accessible location. Users can refer to this summary to see which data are in the repository and some details about them.</p>
<p>Here is a <code>bb_summary</code> of the example data source definitions that are provided as part of the bowerbird package:</p>
<div id="data-group-altimetry" class="section level3">
<h3 class="hasAnchor">
<a href="#data-group-altimetry" class="anchor"></a>Data group: Altimetry</h3>
<div id="cmems-global-gridded-ssh-reprocessed-1993-ongoing" class="section level4">
<h4 class="hasAnchor">
<a href="#cmems-global-gridded-ssh-reprocessed-1993-ongoing" class="anchor"></a>CMEMS global gridded SSH reprocessed (1993-ongoing)</h4>
<p>For the Global Ocean - Multimission altimeter satellite gridded sea surface heights and derived variables computed with respect to a twenty-year mean. Previously distributed by Aviso+, no change in the scientific content. All the missions are homogenized with respect to a reference mission which is currently OSTM/Jason-2. VARIABLES</p>
<ul>
<li><p>sea_surface_height_above_sea_level (SSH)</p></li>
<li><p>surface_geostrophic_eastward_sea_water_velocity_assuming_sea_level_for_geoid (UVG)</p></li>
<li><p>surface_geostrophic_northward_sea_water_velocity_assuming_sea_level_for_geoid (UVG)</p></li>
<li><p>sea_surface_height_above_geoid (SSH)</p></li>
<li><p>surface_geostrophic_eastward_sea_water_velocity (UVG)</p></li>
<li><p>surface_geostrophic_northward_sea_water_velocity (UVG)</p></li>
</ul>
<p>Authentication note: Copernicus Marine login required, see <a href="http://marine.copernicus.eu/services-portfolio/register-now/" class="uri">http://marine.copernicus.eu/services-portfolio/register-now/</a></p>
<p>Approximate size: 310 GB</p>
<p>Documentation link: <a href="http://cmems-resources.cls.fr/?option=com_csw&amp;view=details&amp;tab=info&amp;product_id=SEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047" class="uri">http://cmems-resources.cls.fr/?option=com_csw&amp;view=details&amp;tab=info&amp;product_id=SEALEVEL_GLO_PHY_L4_REP_OBSERVATIONS_008_047</a></p>
</div>
</div>
<div id="data-group-electoral" class="section level3">
<h3 class="hasAnchor">
<a href="#data-group-electoral" class="anchor"></a>Data group: Electoral</h3>
<div id="australian-election-2016-house-of-representatives-data" class="section level4">
<h4 class="hasAnchor">
<a href="#australian-election-2016-house-of-representatives-data" class="anchor"></a>Australian Election 2016 House of Representatives data</h4>
<p>House of Representatives results from the 2016 Australian election.</p>
<p>Approximate size: 0.01 GB</p>
<p>Documentation link: <a href="http://results.aec.gov.au/" class="uri">http://results.aec.gov.au/</a></p>
</div>
</div>
<div id="data-group-ocean-colour" class="section level3">
<h3 class="hasAnchor">
<a href="#data-group-ocean-colour" class="anchor"></a>Data group: Ocean colour</h3>
<div id="oceandata-seawifs-level-3-mapped-monthly-9km-chl-a" class="section level4">
<h4 class="hasAnchor">
<a href="#oceandata-seawifs-level-3-mapped-monthly-9km-chl-a" class="anchor"></a>Oceandata SeaWiFS Level-3 mapped monthly 9km chl-a</h4>
<p>Monthly remote-sensing chlorophyll-a from the SeaWiFS satellite at 9km spatial resolution</p>
<p>Approximate size: 7.2 GB</p>
<p>Documentation link: <a href="https://oceancolor.gsfc.nasa.gov/" class="uri">https://oceancolor.gsfc.nasa.gov/</a></p>
</div>
</div>
<div id="data-group-sea-ice" class="section level3">
<h3 class="hasAnchor">
<a href="#data-group-sea-ice" class="anchor"></a>Data group: Sea ice</h3>
<div id="sea-ice-trends-and-climatologies-from-smmr-and-ssmi-ssmis-version-2" class="section level4">
<h4 class="hasAnchor">
<a href="#sea-ice-trends-and-climatologies-from-smmr-and-ssmi-ssmis-version-2" class="anchor"></a>Sea Ice Trends and Climatologies from SMMR and SSM/I-SSMIS, Version 2</h4>
<p>NSIDC provides this data set to aid in the investigations of the variability and trends of sea ice cover. Ice cover in these data are indicated by sea ice concentration: the percentage of the ocean surface covered by ice. The ice-covered area indicates how much ice is present; it is the total area of a pixel multiplied by the ice concentration in that pixel. Ice persistence is the percentage of months over the data set time period that ice existed at a location. The ice-extent indicates whether ice is present; here, ice is considered to exist in a pixel if the sea ice concentration exceeds 15 percent. This data set provides users with data about total ice-covered areas, sea ice extent, ice persistence, and monthly climatologies of sea ice concentrations.</p>
<p>Authentication note: Requires Earthdata login, see <a href="https://wiki.earthdata.nasa.gov/display/EL/How+To+Register+With+Earthdata+Login" class="uri">https://wiki.earthdata.nasa.gov/display/EL/How+To+Register+With+Earthdata+Login</a> . Note that you will also need to authorize the application ‘nsidc-daacdata’ (see ‘My Applications’ at <a href="https://urs.earthdata.nasa.gov/profile" class="uri">https://urs.earthdata.nasa.gov/profile</a>)</p>
<p>Approximate size: 0.02 GB</p>
<p>Documentation link: <a href="https://nsidc.org/data/NSIDC-0192/versions/2" class="uri">https://nsidc.org/data/NSIDC-0192/versions/2</a></p>
</div>
</div>
<div id="data-group-sea-surface-temperature" class="section level3">
<h3 class="hasAnchor">
<a href="#data-group-sea-surface-temperature" class="anchor"></a>Data group: Sea surface temperature</h3>
<div id="noaa-oi-sst-v2" class="section level4">
<h4 class="hasAnchor">
<a href="#noaa-oi-sst-v2" class="anchor"></a>NOAA OI SST V2</h4>
<p>Weekly and monthly mean and long-term monthly mean SST data, 1-degree resolution, 1981 to present. Ice concentration data are also included, which are the ice concentration values input to the SST analysis</p>
<p>Approximate size: 0.9 GB</p>
<p>Documentation link: <a href="http://www.esrl.noaa.gov/psd/data/gridded/data.noaa.oisst.v2.html" class="uri">http://www.esrl.noaa.gov/psd/data/gridded/data.noaa.oisst.v2.html</a></p>
</div>
</div>
<div id="data-group-topography" class="section level3">
<h3 class="hasAnchor">
<a href="#data-group-topography" class="anchor"></a>Data group: Topography</h3>
<div id="bathymetry-of-lake-superior" class="section level4">
<h4 class="hasAnchor">
<a href="#bathymetry-of-lake-superior" class="anchor"></a>Bathymetry of Lake Superior</h4>
<p>A draft version of the Lake Superior Bathymetry was compiled as a component of a NOAA project to rescue Great Lakes lake floor geological and geophysical data, and make it more accessible to the public. No time frame has been set for completing bathymetric contours of Lake Superior, though a 3 arc-second (~90 meter cell size) grid is available.</p>
<p>Approximate size: 0.03 GB</p>
<p>Documentation link: <a href="https://www.ngdc.noaa.gov/mgg/greatlakes/superior.html" class="uri">https://www.ngdc.noaa.gov/mgg/greatlakes/superior.html</a></p>
</div>
</div>
</div>
</div>
</div>
  </div>

  <div class="col-md-3 hidden-xs hidden-sm" id="sidebar">
        <div id="tocnav">
      <h2 class="hasAnchor">
<a href="#tocnav" class="anchor"></a>Contents</h2>
      <ul class="nav nav-pills nav-stacked">
<li>
<a href="#bowerbird">Bowerbird</a><ul class="nav nav-pills nav-stacked">
<li><a href="#installing">Installing</a></li>
      <li><a href="#usage-overview">Usage overview</a></li>
      <li><a href="#users-level-of-usage-and-expected-knowledge">Users: level of usage and expected knowledge</a></li>
      <li><a href="#defining-data-sources">Defining data sources</a></li>
      <li><a href="#nuances">Nuances</a></li>
      <li><a href="#developer-notes">Developer notes</a></li>
      <li><a href="#data-source-summary">Data source summary</a></li>
      </ul>
</li>
      </ul>
</div>
      </div>

</div>


      <footer><div class="copyright">
  <p>Developed by Ben Raymond, Michael Sumner.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="http://pkgdown.r-lib.org/">pkgdown</a>.</p>
</div>

      </footer>
</div>

  </body>
</html>
